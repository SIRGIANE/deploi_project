services:
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.train
    ports:
      - "8889:8888"
    volumes:
      - ./:/workspace
    working_dir: /workspace
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=''

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.train
    ports:
      - "5050:5000"
    volumes:
      - ./:/workspace
      - mlflow_data:/mlruns
    working_dir: /workspace
    command: mlflow server --host 0.0.0.0 --port 5000

  # Airflow PostgreSQL Database
  airflow-postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_db_volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  # Redis for Airflow Celery
  redis:
    image: redis:latest
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  # Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/workspace
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    command: webserver

  # Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/workspace
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8793/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    command: scheduler

  # Airflow Worker
  airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/workspace
    healthcheck:
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      DUMB_INIT_SETSID: "0"
    restart: always
    command: celery worker

  # Airflow Init
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    entrypoint: /bin/bash
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/workspace
    environment:
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: 'admin'
      _AIRFLOW_WWW_USER_PASSWORD: 'admin'
    user: "50000:0"
    command:
      - -c
      - |
        mkdir -p /opt/airflow/{logs,dags,config,plugins}
        chown -R airflow:root /opt/airflow/{logs,dags,config,plugins}
        airflow db upgrade
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true

  # Database pour les données Météo
  weather-db:
    image: postgres:13
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: weather_data
    volumes:
      - weather_db_volume:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "user", "-d", "weather_data"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

volumes:
  mlflow_data:
  postgres_db_volume:
  weather_db_volume: