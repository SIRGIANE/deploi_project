# ğŸ—ï¸ Architecture des ModÃ¨les Machine Learning - Climate MLOps

## ğŸ“‹ Vue d'ensemble du systÃ¨me

Ce document dÃ©crit l'architecture des modÃ¨les de machine learning utilisÃ©s dans le projet Climate MLOps pour la prÃ©diction mÃ©tÃ©orologique de Marrakech.

### ğŸ¯ Objectif
PrÃ©dire les variables mÃ©tÃ©orologiques (tempÃ©rature max, min, moyenne) basÃ©es sur les donnÃ©es historiques de 2018-2023.

---

## ğŸ§  ModÃ¨les ImplÃ©mentÃ©s

### 1. ğŸ“Š **Linear Regression (Baseline)**
**Type :** ModÃ¨le de rÃ©fÃ©rence (baseline)  
**Algorithme :** RÃ©gression linÃ©aire multiple  
**Classe utilisÃ©e :** `sklearn.linear_model.LinearRegression`

#### CaractÃ©ristiques :
- **ComplexitÃ© :** Faible
- **InterprÃ©tabilitÃ© :** TrÃ¨s Ã©levÃ©e
- **Temps d'entraÃ®nement :** TrÃ¨s rapide
- **CapacitÃ© de gÃ©nÃ©ralisation :** LimitÃ©e pour les relations non-linÃ©aires

#### ParamÃ¨tres :
```python
# Aucun hyperparamÃ¨tre Ã  ajuster
model = LinearRegression()
```

#### Usage :
- ModÃ¨le de rÃ©fÃ©rence pour comparaison
- Ã‰tablissement de la performance minimale acceptable
- Validation que les features ont un signal prÃ©dictif

---

### 2. ğŸŒ² **Random Forest Regressor (ModÃ¨le Principal)**
**Type :** Ensemble de modÃ¨les - Bagging  
**Algorithme :** ForÃªt alÃ©atoire de rÃ©gresseurs  
**Classe utilisÃ©e :** `sklearn.ensemble.RandomForestRegressor`

#### CaractÃ©ristiques :
- **ComplexitÃ© :** Moyenne Ã  Ã©levÃ©e
- **InterprÃ©tabilitÃ© :** Moyenne (feature importance disponible)
- **Temps d'entraÃ®nement :** ModÃ©rÃ©
- **RÃ©sistance au surapprentissage :** Ã‰levÃ©e
- **Gestion des valeurs manquantes :** Naturelle
- **ParallÃ©lisation :** Oui (n_jobs=-1)

#### ParamÃ¨tres par dÃ©faut :
```python
DEFAULT_RF_PARAMS = {
    'n_estimators': 200,        # Nombre d'arbres dans la forÃªt
    'max_depth': 15,            # Profondeur maximale des arbres
    'min_samples_split': 5,     # Ã‰chantillons min pour diviser un nÅ“ud
    'min_samples_leaf': 2,      # Ã‰chantillons min dans une feuille
    'random_state': 42          # ReproductibilitÃ©
}
```

#### Optimisation Optuna :
```python
OPTUNA_RF_SEARCH_SPACE = {
    'n_estimators': (50, 500),      # Plage d'optimisation
    'max_depth': (5, 30),
    'min_samples_split': (2, 20),
    'min_samples_leaf': (1, 10)
}
```

#### Avantages :
- âœ… Excellent Ã©quilibre performance/robustesse
- âœ… GÃ¨re naturellement les interactions entre features
- âœ… Fournit l'importance des variables
- âœ… RÃ©sistant aux outliers
- âœ… Peu sensible aux hyperparamÃ¨tres

#### Cas d'usage :
- ModÃ¨le principal de production
- PrÃ©dictions mÃ©tÃ©orologiques quotidiennes
- Analyse d'importance des features climatiques

---

### 3. ğŸ“ˆ **Gradient Boosting Regressor**
**Type :** Ensemble de modÃ¨les - Boosting  
**Algorithme :** Gradient Boosting sÃ©quentiel  
**Classe utilisÃ©e :** `sklearn.ensemble.GradientBoostingRegressor` avec `MultiOutputRegressor`

#### CaractÃ©ristiques :
- **ComplexitÃ© :** Ã‰levÃ©e
- **InterprÃ©tabilitÃ© :** Faible Ã  moyenne
- **Temps d'entraÃ®nement :** Plus lent (sÃ©quentiel)
- **Performance :** Potentiellement supÃ©rieure avec bon tuning
- **SensibilitÃ© au surapprentissage :** ModÃ©rÃ©e

#### ParamÃ¨tres par dÃ©faut :
```python
GB_PARAMS = {
    'n_estimators': 150,        # Nombre d'arbres boost
    'learning_rate': 0.1,       # Taux d'apprentissage
    'max_depth': 6,             # Profondeur des arbres faibles
    'random_state': 42
}
```

#### Avantages :
- âœ… Apprentissage sÃ©quentiel des erreurs
- âœ… Souvent performance supÃ©rieure
- âœ… ContrÃ´le fin via learning_rate
- âœ… Gestion des patterns complexes

#### InconvÃ©nients :
- âŒ Plus sensible au surapprentissage
- âŒ Temps d'entraÃ®nement plus long
- âŒ Plus de hyperparamÃ¨tres Ã  ajuster

---

## ğŸ—ï¸ Architecture du Pipeline ML

### Pipeline de DonnÃ©es
```
Raw Data â†’ Feature Engineering â†’ Scaling â†’ Train/Test Split â†’ Models
```

#### Features Engineering :
```python
FEATURE_COLUMNS = [
    # Temporelles
    'Year', 'Month', 'Quarter', 'DayOfYear', 'WeekOfYear',
    
    # Cycliques (trigonomÃ©triques)
    'Month_sin', 'Month_cos', 
    'DayOfYear_sin', 'DayOfYear_cos',
    
    # Lag features (valeurs passÃ©es)
    'Temp_lag_1', 'Temp_lag_3', 'Temp_lag_7', 
    'Temp_lag_14', 'Temp_lag_30',
    
    # Moving averages
    'Temp_ma_3', 'Temp_ma_7', 'Temp_ma_14', 'Temp_ma_30',
    
    # Tendances et volatilitÃ©
    'Temp_trend_30d', 'Temp_volatility_7d',
    
    # DiffÃ©rences
    'Temp_diff_1d', 'Temp_diff_7d'
]
```

#### Variables Cibles :
```python
TARGET_VARIABLES = [
    'temperature_2m_max (Â°C)',
    'temperature_2m_min (Â°C)', 
    'temperature_2m_mean (Â°C)'
]
```

---

## ğŸ“Š MÃ©triques d'Ã‰valuation

### MÃ©triques CalculÃ©es :
```python
EVALUATION_METRICS = [
    'rmse',           # Root Mean Square Error
    'mae',            # Mean Absolute Error  
    'r2_score',       # Coefficient de dÃ©termination
    'mape'            # Mean Absolute Percentage Error
]
```

### Calcul Multi-target :
- MÃ©triques individuelles par variable cible
- Moyennes globales pour comparaison des modÃ¨les
- MÃ©triques train/test pour dÃ©tecter le surapprentissage

---

## ğŸ”§ Configuration et Optimisation

### Optimisation HyperparamÃ¨tres (Optuna) :
```python
HYPERPARAMETER_OPTIMIZATION = {
    'enabled': True,
    'method': 'optuna',
    'trials': 100,
    'timeout_seconds': 7200,  # 2 heures max
    'objective': 'minimize_rmse'
}
```

### Validation CroisÃ©e :
```python
CROSS_VALIDATION = {
    'folds': 5,
    'strategy': 'time_series_split',  # Respecte l'ordre temporel
    'test_size': 0.2,
    'validation_size': 0.1
}
```

---

## ğŸš€ StratÃ©gie de DÃ©ploiement

### SÃ©lection du ModÃ¨le :
1. **EntraÃ®nement** des 3 modÃ¨les en parallÃ¨le
2. **Comparaison** basÃ©e sur RMSE moyen
3. **SÃ©lection automatique** du meilleur modÃ¨le
4. **Sauvegarde** avec versioning MLflow

### CritÃ¨res de Promotion :
```python
MODEL_PROMOTION_CRITERIA = {
    'min_rmse_improvement': 0.05,       # 5% d'amÃ©lioration min
    'min_r2_improvement': 0.02,         # 2% d'amÃ©lioration RÂ²
    'min_data_points': 100,             # DonnÃ©es d'Ã©valuation min
    'max_training_time_seconds': 3600,  # Temps max acceptable
    'require_positive_tests': True      # Tous tests passent
}
```

---

## ğŸ“ˆ Monitoring et MLOps

### Tracking MLflow :
- **ParamÃ¨tres** : Tous hyperparamÃ¨tres
- **MÃ©triques** : RMSE, MAE, RÂ² par cible
- **Artefacts** : ModÃ¨les sÃ©rialisÃ©s, scalers, pipelines
- **Tags** : Version, environnement, dataset

### Continuous Training :
```python
RETRAINING_CONFIG = {
    'enabled': True,
    'interval_days': 7,           # Hebdomadaire
    'new_data_buffer_size': 7,    # Attendre 7 jours de nouvelles donnÃ©es
    'performance_threshold': 0.05  # Seuil de dÃ©gradation
}
```

### Data Drift Detection :
```python
DRIFT_DETECTION = {
    'enabled': True,
    'method': 'statistical',      # KS test, ChiÂ²
    'threshold': 0.3,
    'window_size': 30,           # 30 jours
    'min_samples': 100
}
```

---

## ğŸ’¾ Persistence et Versioning

### Sauvegarde ModÃ¨les :
```
models/
â”œâ”€â”€ rf_model.pkl              # Random Forest sÃ©rialisÃ©
â”œâ”€â”€ scaler.pkl               # StandardScaler
â”œâ”€â”€ data_pipeline.joblib     # Pipeline complet
â””â”€â”€ registry/
    â”œâ”€â”€ staging/             # ModÃ¨les en validation
    â”œâ”€â”€ production/          # ModÃ¨le actuel en prod
    â””â”€â”€ archive/            # Versions archivÃ©es
```

### MÃ©tadonnÃ©es :
```json
{
    "model_type": "RandomForest",
    "version": "v2.1.0",
    "training_date": "2024-12-13T10:30:00",
    "performance": {
        "avg_test_rmse": 2.45,
        "avg_test_r2": 0.87,
        "avg_test_mae": 1.92
    },
    "hyperparameters": {
        "n_estimators": 200,
        "max_depth": 15
    },
    "features": ["Year", "Month", "Temp_lag_1", ...],
    "targets": ["temperature_2m_max", "temperature_2m_min", "temperature_2m_mean"]
}
```

---

## ğŸ¯ Recommandations d'Usage

### Pour la Production :
1. **Utiliser Random Forest** comme modÃ¨le principal
2. **Gradient Boosting** pour cas complexes/saisonniers
3. **Linear Regression** comme fallback rapide

### Pour l'AmÃ©lioration :
1. Ajouter des features mÃ©tÃ©orologiques externes
2. ImplÃ©menter des modÃ¨les deep learning (LSTM)
3. Enrichir avec donnÃ©es satellites
4. A/B testing entre modÃ¨les

### Pour le Monitoring :
1. Surveiller la dÃ©rive des donnÃ©es d'entrÃ©e
2. Tracker les performances en temps rÃ©el  
3. Alertes automatiques si dÃ©gradation
4. Retraining dÃ©clenchÃ© par seuils

---

*ğŸ“… Document mis Ã  jour le : 13 dÃ©cembre 2024*  
*ğŸ”„ Version : 1.0*  
*ğŸ‘¨â€ğŸ’» GÃ©nÃ©rÃ© automatiquement par Climate MLOps*