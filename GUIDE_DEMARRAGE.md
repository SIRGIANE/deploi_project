# üå°Ô∏è Guide Complet de D√©marrage - Climate MLOps

## üìã Table des Mati√®res
1. [D√©marrage Rapide](#d√©marrage-rapide)
2. [D√©tails des Services](#d√©tails-des-services)
3. [MLflow - Configuration et Utilisation](#mlflow---configuration-et-utilisation)
4. [Apache Airflow - Configuration et DAGs](#apache-airflow---configuration-et-dags)
5. [Dashboard - Guide Complet](#dashboard---guide-complet)
6. [Troubleshooting](#troubleshooting)

---

## üöÄ D√©marrage Rapide


```bash
# Depuis le r√©pertoire climate-mlops
./START.sh
```

Cela d√©marrera:
- ‚úÖ **API FastAPI** (port 8000) avec Dashboard
- ‚úÖ **MLflow** (port 5050) pour le tracking des mod√®les

### Option 2: D√©marrage Complet avec Airflow (Docker Compose)

```bash
# D√©marrage de TOUS les services (API + MLflow + Airflow + Databases)
./START.sh full
```

Cela d√©marrera:
- ‚úÖ **API FastAPI** (port 8000)
- ‚úÖ **MLflow** (port 5050)
- ‚úÖ **Airflow Webserver** (port 8080) - Interface web
- ‚úÖ **Airflow Scheduler** - Planification automatique
- ‚úÖ **Airflow Worker** - Ex√©cution des t√¢ches
- ‚úÖ **PostgreSQL** - Base de donn√©es Airflow
- ‚úÖ **Redis** - Broker Celery pour les workers

### Arr√™t des Services

```bash
# Option 1 (si utilisation de START.sh simple)
./STOP.sh

# Option 2 (si utilisation de Docker Compose)
docker-compose down
```

---

## üìä D√©tails des Services

### 1. API FastAPI (Port 8000)

**URL**: http://localhost:8000

**Endpoints disponibles:**
- **Dashboard**: http://localhost:8000/dashboard
  - Visualisation des donn√©es m√©t√©o
  - Graphiques en temps r√©el
  - Comparaison pr√©dictions vs r√©alit√©
  
- **API Documentation**: http://localhost:8000/docs
  - Swagger UI complet
  - Testez les endpoints directement
  
- **Interface Web**: http://localhost:8000/web
  - Formulaire de pr√©diction manuelle
  
- **Health Check**: http://localhost:8000/health
  - V√©rification de l'√©tat de l'API

**Endpoints cl√©s:**
```bash
# Sant√© de l'API
curl http://localhost:8000/health

# Lister les mod√®les disponibles
curl http://localhost:8000/models

# Pr√©diction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": {"Year": 2024, "Month": 6, ...}}'
```

### 2. MLflow (Port 5050)

**URL**: http://localhost:5050

**Fonctionnalit√©s:**
- Tracking des exp√©riences d'entra√Ænement
- Visualisation des m√©triques
- Gestion des versions de mod√®les
- Comparaison entre runs

**Structure:**
```
MLflow/
‚îú‚îÄ‚îÄ Exp√©riences
‚îÇ   ‚îî‚îÄ‚îÄ Climate_Marrakech
‚îÇ       ‚îú‚îÄ‚îÄ Run 1: RandomForest (R¬≤ = 0.98)
‚îÇ       ‚îú‚îÄ‚îÄ Run 2: GradientBoosting (R¬≤ = 0.96)
‚îÇ       ‚îî‚îÄ‚îÄ Run 3: LinearRegression (baseline)
‚îú‚îÄ‚îÄ M√©triques
‚îÇ   ‚îú‚îÄ‚îÄ temperature_2m_mean_r2
‚îÇ   ‚îú‚îÄ‚îÄ temperature_2m_max_rmse
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ Artefacts
    ‚îú‚îÄ‚îÄ rf_model.pkl
    ‚îú‚îÄ‚îÄ scaler.pkl
    ‚îî‚îÄ‚îÄ data_pipeline.joblib
```

---

## üîÑ MLflow - Configuration et Utilisation

### Configuration Automatique

MLflow est configur√© automatiquement avec:
- **Backend Local**: `mlruns/` (fichiers locaux)
- **Exp√©rience**: `Climate_Marrakech`
- **Artifacts**: `mlruns/artifacts/`

### Entra√Æner un Mod√®le et le Tracker dans MLflow

```bash
# Lancer l'entra√Ænement complet (cr√©e automatiquement des runs MLflow)
python src/train_model.py

# Ou sp√©cifier une exp√©rience personnalis√©e
python src/train_model.py \
  --mlflow-uri "http://localhost:5050" \
  --experiment-name "Custom_Experiment"
```

### Visualiser les R√©sultats dans MLflow

1. Ouvrez: http://localhost:5050
2. Allez dans **Experiments** ‚Üí **Climate_Marrakech**
3. Comparez les mod√®les:
   - Cliquez sur les runs pour voir les d√©tails
   - Comparez les m√©triques entre mod√®les
   - T√©l√©chargez les mod√®les sauvegard√©s

### R√©cup√©rer un Mod√®le depuis MLflow

```python
import mlflow

# Se connecter √† MLflow
mlflow.set_tracking_uri("file:./mlruns")

# Charger un mod√®le sp√©cifique
model_uri = "runs:/RUN_ID/random_forest_model"
model = mlflow.sklearn.load_model(model_uri)

# Ou charger la version de production
model_uri = "models:/climate-model/production"
model = mlflow.sklearn.load_model(model_uri)
```

---

## üîÄ Apache Airflow - Configuration et DAGs

### üöÄ D√©marrage d'Airflow

```bash
# D√©marrer Airflow complet avec Docker Compose
./START.sh full

# Ou manuellement
docker-compose up -d airflow-postgres redis airflow-init airflow-webserver airflow-scheduler airflow-worker

# Attendre ~30 secondes que tout d√©marre
sleep 30
```

### üìä Acc√®s √† l'Interface Airflow

**URL**: http://localhost:8080

**Identifiants:**
- **Username**: `admin`
- **Password**: `admin`

### üèóÔ∏è Architecture d'Airflow

```
Airflow/
‚îú‚îÄ‚îÄ Webserver (Port 8080)          ‚Üê Interface web
‚îú‚îÄ‚îÄ Scheduler                       ‚Üê Planification des DAGs
‚îú‚îÄ‚îÄ Worker (Celery)                ‚Üê Ex√©cution des t√¢ches
‚îú‚îÄ‚îÄ PostgreSQL (Port 5432)         ‚Üê Base de donn√©es
‚îú‚îÄ‚îÄ Redis (Port 6379)              ‚Üê Message broker
‚îÇ
‚îî‚îÄ‚îÄ DAG: climate_data_pipeline
    ‚îú‚îÄ‚îÄ step1_load_data            (Charger donn√©es brutes)
    ‚îú‚îÄ‚îÄ step2_preprocess_data      (Pr√©traiter)
    ‚îú‚îÄ‚îÄ step3_create_features      (Feature engineering)
    ‚îú‚îÄ‚îÄ step4_train_model          (Entra√Æner RandomForest)
    ‚îú‚îÄ‚îÄ step5_validate_api         (V√©rifier API)
    ‚îî‚îÄ‚îÄ notify_success             (Notification de succ√®s)
```

### üéØ Pipeline de Donn√©es Airflow

Le DAG ex√©cute automatiquement le pipeline complet:

1. **step1_load_data** (5 min)
   - Charge les donn√©es brutes depuis `marrakech_weather_2018_2023_final.csv`
   - Logs dans MLflow: `raw_data_rows`, `raw_data_cols`

2. **step2_preprocess_data** (2 min)
   - Pr√©traite les donn√©es (nettoyage, normalisation)
   - Logs dans MLflow: `processed_data_rows`, `processed_data_cols`

3. **step3_create_features** (3 min)
   - Cr√©e 49 features avanc√©es
   - Logs dans MLflow: `features_rows`, `features_cols`

4. **step4_train_model** (10 min)
   - Entra√Æne le RandomForest
   - Logs dans MLflow: m√©triques R¬≤, RMSE, MAE

5. **step5_validate_api** (1 min)
   - V√©rifie que l'API est op√©rationnelle

6. **notify_success**
   - Affiche un message de succ√®s

**Dur√©e totale**: ~20 minutes

### ‚è∞ Planification du DAG

Le DAG s'ex√©cute **automatiquement chaque jour √† minuit** (UTC).

**Modifier la fr√©quence:**

√âditez `airflow/dags/climate_pipeline_dag.py`:

```python
dag = DAG(
    'climate_data_pipeline',
    default_args=default_args,
    schedule_interval='@daily',          # ‚Üê Modifier ici
    # schedule_interval='@hourly',       # Horaire
    # schedule_interval='0 0 * * *',     # Personnalis√© (minuit UTC)
    # schedule_interval='0 6 * * *',     # 6h du matin UTC
    catchup=False,
)
```

### üéÆ Contr√¥ler le DAG depuis l'Interface Web

#### Activer/D√©sactiver le DAG

1. Allez √†: http://localhost:8080
2. Recherchez le DAG: `climate_data_pipeline`
3. Cliquez sur le **toggle** pour activer/d√©sactiver

#### D√©clencher Manuellement

1. Allez √†: http://localhost:8080/dags/climate_data_pipeline
2. Cliquez sur le bouton **"Trigger DAG"** (en haut √† droite)
3. Optionnel: Entrez une date de d√©marrage personnalis√©e

#### Voir les Logs des T√¢ches

1. Allez √†: http://localhost:8080/dags/climate_data_pipeline
2. Cliquez sur **"Graph View"** ou **"Tree View"**
3. Cliquez sur une t√¢che (rectangle)
4. Allez dans l'onglet **"Logs"**

#### Visualiser l'Ex√©cution

1. **Tree View**: Timeline verticale de l'ex√©cution
2. **Graph View**: DAG en diagramme
3. **Gantt Chart**: Timeline horizontale avec dur√©es
4. **Calendar**: Historique des ex√©cutions

### üîó Int√©gration Airflow + MLflow

Le DAG se connecte automatiquement √† MLflow:

```python
mlflow.set_experiment("Climate_Marrakech_Airflow")
with mlflow.start_run(run_name="step1_load_data"):
    # Les m√©triques s'enregistrent automatiquement
    mlflow.log_metric("raw_data_rows", 2191)
```

**Visualiser dans MLflow:**
1. Ouvrez: http://localhost:5050
2. Allez √† **Experiments** ‚Üí **Climate_Marrakech_Airflow**
3. Cliquez sur les runs cr√©√©s par Airflow

### üêõ D√©panner les T√¢ches Airflow

#### Voir les Logs D√©taill√©s

```bash
# Logs d'une t√¢che sp√©cifique
docker-compose logs airflow-scheduler 2>&1 | tail -100

# Logs du worker
docker-compose logs airflow-worker 2>&1 | tail -100

# Tous les logs Airflow
docker-compose logs -f airflow-webserver airflow-scheduler airflow-worker
```

#### Tester le DAG Localement

```bash
# Tester une seule t√¢che
docker-compose exec airflow-webserver airflow tasks test climate_data_pipeline step1_load_data 2024-12-13

# Tester le DAG complet (sans scheduler)
docker-compose exec airflow-webserver airflow dags test climate_data_pipeline 2024-12-13
```

#### V√©rifier la Connexion √† PostgreSQL

```bash
# Acc√©dez √† la base de donn√©es Airflow
docker-compose exec airflow-postgres psql -U airflow -d airflow

# Lister les tables
\dt

# Lister les DAGs
select dag_id, is_paused from dag;

# Quitter
\q
```

#### Reset Complet d'Airflow

```bash
# ‚ö†Ô∏è  ATTENTION: Cela supprime tous les donn√©es et logs!

docker-compose down -v

# Red√©marrer
docker-compose up -d
```

---

## üìä Dashboard - Guide Complet

### Acc√®s au Dashboard

**URL**: http://localhost:8000/dashboard

### Fonctionnalit√©s

#### 1. **KPI Cards** (Haut de page)
- Temp√©rature actuelle (min/max/moyenne)
- Humidit√© relative
- Vitesse du vent
- Pr√©cipitations

#### 2. **Graphiques Interactifs**
- **Temp√©ratures**: √âvolution min/max/moyenne sur 7 jours
- **Humidit√©**: Variation quotidienne
- **Pr√©cipitations**: Cumuls quotidiens
- **Vent**: Vitesse maximale

#### 3. **Section Pr√©dictions**
- Affiche les pr√©dictions du mod√®le ML pour le prochain jour
- Comparaison avec les donn√©es r√©elles historiques

#### 4. **Tableau de Comparaison**
| Date | R√©el Temp | Pr√©diction | √âcart | Erreur % |
|------|-----------|------------|-------|----------|
| 2024-12-13 | 22.5¬∞C | 22.8¬∞C | +0.3¬∞C | 1.3% |
| 2024-12-12 | 21.2¬∞C | 21.0¬∞C | -0.2¬∞C | 0.9% |

#### 5. **T√©l√©chargement**
- Bouton pour t√©l√©charger les graphiques en PNG
- Export des donn√©es en CSV (√† venir)

### Mode Clair/Sombre

Basculez avec le bouton en haut √† droite du dashboard.

Votre pr√©f√©rence est sauvegard√©e localement (localStorage).

### Filtrage des Donn√©es

S√©lectionnez une plage de dates pour zoomer sur des p√©riodes sp√©cifiques.

---

## üîß D√©marrage Complet Pas √† Pas

### √âtape 1: Installation des d√©pendances (premi√®re fois seulement)

```bash
# Option A: Pip (rapide)
pip install -r requirements.txt

# Option B: Conda (isolation compl√®te)
conda create -n climate-mlops python=3.10
conda activate climate-mlops
pip install -r requirements.txt
```

### √âtape 2: D√©marrer les services

```bash
# Mode simple (API + MLflow uniquement)
./START.sh

# Attendez que tout soit pr√™t (~10 secondes)
# Vous verrez:
# ‚úÖ MLflow d√©marr√© (PID: XXXX)
# ‚úÖ API d√©marr√©e (PID: YYYY)
```

### √âtape 3: V√©rifier que tout fonctionne

```bash
# V√©rifier l'API
curl http://localhost:8000/health

# V√©rifier MLflow
curl http://localhost:5050/health || echo "MLflow pr√™t"
```

### √âtape 4: Acc√©dez aux interfaces

Ouvrez dans votre navigateur:
- **Dashboard**: http://localhost:8000/dashboard
- **API Docs**: http://localhost:8000/docs
- **MLflow**: http://localhost:5050

### √âtape 5: Entra√Æner un mod√®le (optionnel)

```bash
# Lance l'entra√Ænement complet
# Les r√©sultats s'afficheront automatiquement dans MLflow
python src/train_model.py
```

---

## üîç V√©rification du Statut

### Afficher les services en cours d'ex√©cution

```bash
# Voir tous les processus Python actifs
ps aux | grep -E "mlflow|uvicorn|python main"

# Voir les logs en temps r√©el
tail -f logs/api.log
tail -f logs/mlflow.log
```

### Tester les Endpoints API

```bash
# Health check
curl http://localhost:8000/health | jq

# Lister les mod√®les
curl http://localhost:8000/models | jq

# Pr√©diction simple
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
      "Year": 2024,
      "Month": 12,
      "Quarter": 4,
      "DayOfYear": 347,
      "WeekOfYear": 50,
      "Month_sin": -0.866,
      "Month_cos": 0.5,
      "DayOfYear_sin": 0.9,
      "DayOfYear_cos": 0.43,
      "Temp_lag_1": 22.5,
      "Temp_lag_3": 23.1,
      "Temp_lag_7": 24.2,
      "Temp_lag_14": 25.0,
      "Temp_lag_30": 26.3,
      "Temp_ma_3": 23.0,
      "Temp_ma_7": 23.5,
      "Temp_ma_14": 24.0,
      "Temp_ma_30": 25.0,
      "Temp_trend_30d": 0.05,
      "Temp_volatility_7d": 1.2,
      "Temp_diff_1d": 0.3,
      "Temp_diff_7d": -0.5
    }
  }' | jq
```

---

## üêõ Troubleshooting

### Probl√®me: "Port 8000 d√©j√† utilis√©"

```bash
# Trouver le processus utilisant le port
lsof -i :8000

# Tuer le processus
kill -9 <PID>

# Ou utiliser un port diff√©rent
API_PORT=8001 python main.py
```

### Probl√®me: "Port 5050 d√©j√† utilis√©"

```bash
# Arr√™ter les instances MLflow existantes
pkill -f "mlflow server"

# Ou utiliser un port diff√©rent
mlflow server --port 5051
```

### Probl√®me: "Dataset non trouv√©"

```bash
# V√©rifier que le fichier existe
ls -lh marrakech_weather_2018_2023_final.csv

# S'il manque, t√©l√©charger depuis Kaggle
# Ou utiliser un autre fichier de donn√©es
```

### Probl√®me: "Erreur d'import dans le code"

```bash
# S'assurer que vous √™tes dans le bon r√©pertoire
cd /Users/macadmin/Desktop/climate-mlops

# V√©rifier les d√©pendances
pip list | grep -E "fastapi|mlflow|scikit-learn|pandas"

# R√©installer si n√©cessaire
pip install -r requirements.txt --force-reinstall
```

### Probl√®me: "MLflow ne se connecte pas √† la base de donn√©es"

```bash
# Supprimer la base de donn√©es corrupted et recommencer
rm -rf mlruns/

# Red√©marrer MLflow
./STOP.sh
./START.sh
```

### Probl√®me: "Les mod√®les ne se sauvegardent pas"

```bash
# V√©rifier que le dossier models/ existe
mkdir -p models

# V√©rifier les permissions
chmod 755 models

# V√©rifier l'espace disque
df -h
```

---

## üìö Commandes Utiles

```bash
# Voir les logs en direct
tail -f logs/api.log

# Compter les lignes du dataset
wc -l marrakech_weather_2018_2023_final.csv

# V√©rifier la structure du dataset
head -5 marrakech_weather_2018_2023_final.csv

# Lancer les tests
pytest tests/ -v

# Lancer une pr√©diction depuis Python
python -c "
from src.api import model_manager
import numpy as np
model_manager.load_models()
features = np.random.randn(1, 49)  # 49 features
result = model_manager.predict('random_forest', features)
print('Pr√©diction:', result)
"
```

---

## üéØ Prochaines √âtapes

1. **Entra√Æner le mod√®le**: `python src/train_model.py`
2. **Visualiser dans MLflow**: http://localhost:5050
3. **Faire des pr√©dictions**: http://localhost:8000/dashboard
4. **Configurer Airflow**: D√©commenter les services Docker Compose
5. **Mettre en production**: Utiliser docker-compose.prod.yml

---

## üìû Support

Si vous avez des probl√®mes:
1. V√©rifiez les logs: `tail -f logs/api.log`
2. Testez la connectivit√©: `curl http://localhost:8000/health`
3. Red√©marrez les services: `./STOP.sh && ./START.sh`
4. Consultez le README.md pour plus de d√©tails
