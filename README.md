# ğŸŒ¡ï¸ Climate MLOps - PrÃ©diction de TempÃ©ratures Climatiques

Un projet MLOps complet pour la prÃ©diction des tempÃ©ratures climatiques utilisant des donnÃ©es historiques de Berkeley Earth.

## ğŸ¯ Objectifs du Projet

- **Analyse exploratoire** des donnÃ©es climatiques (1750-2015)
- **DÃ©veloppement de modÃ¨les ML** (Random Forest, LSTM, ARIMA)
- **Pipeline de donnÃ©es automatisÃ©** avec validation
- **API FastAPI** pour servir les prÃ©dictions
- **Tracking des expÃ©riences** avec MLflow
- **DÃ©ploiement containerisÃ©** avec Docker

## ğŸ—ï¸ Architecture du Projet

```
climate-mlops/
â”œâ”€â”€ ğŸ“Š 01_exploratory_analysis.ipynb    # Analyse exploratoire
â”œâ”€â”€ ğŸ¤– 02_model_development.ipynb       # DÃ©veloppement des modÃ¨les
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ğŸ”§ data_pipeline.py             # Pipeline de donnÃ©es
â”‚   â”œâ”€â”€ ğŸš€ train_model.py               # Script d'entraÃ®nement
â”‚   â””â”€â”€ ğŸŒ api.py                       # API FastAPI
â”œâ”€â”€ ğŸ³ docker-compose.yml               # DÃ©veloppement
â”œâ”€â”€ ğŸ³ docker-compose.prod.yml          # Production
â”œâ”€â”€ ğŸ“¦ requirements.txt                 # DÃ©pendances Python
â””â”€â”€ ğŸ“‹ README.md                        # Documentation
```

## ğŸš€ DÃ©marrage Rapide

### 1. PrÃ©requis
```bash
# Docker et Docker Compose installÃ©s
docker --version
docker-compose --version
```

### 2. Cloner et dÃ©marrer
```bash
git clone <your-repo>
cd climate-mlops

# DÃ©marrage de l'environnement de dÃ©veloppement
docker-compose up -d

# Ou pour la production
docker-compose -f docker-compose.prod.yml up -d
```

### 3. AccÃ¨s aux services
- **ğŸ“Š Jupyter Lab** : http://localhost:8889
- **ğŸ“ˆ MLflow** : http://localhost:5050  
- **ğŸŒ API** : http://localhost:8000 (production uniquement)
- **ğŸ“š Documentation API** : http://localhost:8000/docs

## ğŸ“Š Utilisation

### Analyse Exploratoire
1. Ouvrez Jupyter Lab (http://localhost:8889)
2. ExÃ©cutez `01_exploratory_analysis.ipynb`
3. Visualisez les tendances climatiques historiques

### DÃ©veloppement de ModÃ¨les
1. ExÃ©cutez `02_model_development.ipynb`
2. Suivez l'entraÃ®nement des modÃ¨les :
   - **Random Forest** : ModÃ¨le d'ensemble robuste
   - **LSTM** : RÃ©seau de neurones pour sÃ©ries temporelles
   - **ARIMA** : ModÃ¨le statistique classique
3. Consultez MLflow pour comparer les performances

### EntraÃ®nement AutomatisÃ©
```bash
# EntraÃ®nement de base
docker-compose exec jupyter python src/train_model.py

# Avec optimisation des hyperparamÃ¨tres
docker-compose exec jupyter python src/train_model.py --optimize --trials 100
```

### API de PrÃ©diction
```bash
# Test de l'API
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "year": 2025,
    "month": 12,
    "use_lag_features": true
  }'

# PrÃ©dictions par batch
curl -X POST "http://localhost:8000/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "predictions": [
      {"year": 2025, "month": 1},
      {"year": 2025, "month": 6},
      {"year": 2025, "month": 12}
    ],
    "model_name": "random_forest"
  }'
```

## ğŸ”§ Pipeline de DonnÃ©es

Le pipeline automatisÃ© (`src/data_pipeline.py`) effectue :

1. **Chargement** : DonnÃ©es Kaggle Berkeley Earth
2. **Validation** : ContrÃ´le qualitÃ© automatique
3. **Nettoyage** : Traitement des valeurs manquantes
4. **Feature Engineering** :
   - Features temporelles (annÃ©e, mois, saison)
   - Features cycliques (sin/cos pour saisonnalitÃ©)
   - Features de lag (1, 3, 6, 12 mois)
   - Moyennes mobiles (3, 6, 12 mois)
   - Tendances et volatilitÃ©
5. **Normalisation** : StandardScaler pour ML
6. **Division** : Train/Test temporel (2010 comme split)

## ğŸ¤– ModÃ¨les Disponibles

### Random Forest
- **Type** : Ensemble learning
- **Avantages** : Robuste, interprÃ©table
- **Features** : Importance des variables
- **Performance** : RMSE ~0.5Â°C

### LSTM (Deep Learning)
- **Type** : RÃ©seau de neurones rÃ©current
- **Avantages** : Capture les dÃ©pendances temporelles
- **Architecture** : 2 couches LSTM + Dense
- **SÃ©quences** : 12 mois de contexte

### RÃ©gression LinÃ©aire (Baseline)
- **Type** : ModÃ¨le de rÃ©fÃ©rence
- **Usage** : Comparaison de performance
- **SimplicitÃ©** : InterprÃ©tation facile

## ğŸ“ˆ MLflow Tracking

Toutes les expÃ©riences sont trackÃ©es automatiquement :

- **ParamÃ¨tres** : HyperparamÃ¨tres des modÃ¨les
- **MÃ©triques** : RMSE, MAE, RÂ²
- **Artifacts** : ModÃ¨les sauvegardÃ©s
- **Comparaison** : Interface web intuitive

```python
# AccÃ¨s programmatique
import mlflow
mlflow.set_tracking_uri("http://localhost:5050")
runs = mlflow.search_runs(experiment_ids=["1"])
```

## ğŸŒ API Documentation

### Endpoints Principaux

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Info de l'API |
| `/health` | GET | Status de santÃ© |
| `/models` | GET | Liste des modÃ¨les |
| `/predict` | POST | PrÃ©diction unique |
| `/predict/batch` | POST | PrÃ©dictions multiples |
| `/retrain` | POST | RÃ©entraÃ®nement |

### Exemple de RÃ©ponse
```json
{
  "predicted_temperature": 9.23,
  "confidence_interval": {
    "lower": 8.73,
    "upper": 9.73
  },
  "model_used": "random_forest",
  "prediction_date": "2024-12-02T15:30:00",
  "input_features": {
    "year": 2025,
    "month": 12,
    "model_type": "sklearn"
  }
}
```

## ğŸ”„ Optimisation des HyperparamÃ¨tres

Utilisation d'**Optuna** pour l'optimisation automatique :

```python
# Dans train_model.py
best_params = {
    'n_estimators': 250,
    'max_depth': 20,
    'min_samples_split': 3,
    'min_samples_leaf': 1
}
```

## ğŸ“Š MÃ©triques de Performance

### Ã‰valuation
- **RMSE** : Root Mean Square Error
- **MAE** : Mean Absolute Error  
- **RÂ²** : Coefficient de dÃ©termination
- **Validation temporelle** : Split chronologique

### RÃ©sultats Typiques
- **Random Forest** : RMSE ~0.4Â°C, RÂ² ~0.95
- **LSTM** : RMSE ~0.5Â°C, RÂ² ~0.93
- **Baseline** : RMSE ~0.8Â°C, RÂ² ~0.85

## ğŸ³ DÃ©ploiement

### DÃ©veloppement
```bash
docker-compose up -d
# Services : Jupyter + MLflow
```

### Production
```bash
docker-compose -f docker-compose.prod.yml up -d
# Services : API + MLflow + Jupyter + Scheduler
```

### Monitoring
- **Health checks** automatiques
- **Restart policies** configurÃ©es
- **Logs** centralisÃ©s avec Docker

## ğŸ”§ Configuration

### Variables d'Environnement
```env
MLFLOW_TRACKING_URI=http://localhost:5050
PYTHONPATH=/workspace/src
```

### Ports
- **8889** : Jupyter Lab
- **5050** : MLflow UI  
- **8000** : API FastAPI

## ğŸ“ DÃ©veloppement

### Installation locale
```bash
pip install -r requirements.txt
```

### Tests
```bash
pytest tests/
```

### Formatage du code
```bash
black src/
flake8 src/
```

## ğŸš€ Prochaines Ã‰tapes

1. **Tests unitaires** : Couverture complÃ¨te
2. **CI/CD** : GitHub Actions
3. **Monitoring avancÃ©** : Prometheus + Grafana
4. **Data drift detection** : Evidently AI
5. **A/B Testing** : Comparaison de modÃ¨les en production
6. **Scaling** : Kubernetes deployment

## ğŸ“š Ressources

- **DonnÃ©es** : [Berkeley Earth](http://berkeleyearth.org/data/)
- **MLflow** : [Documentation](https://mlflow.org/docs/latest/index.html)
- **FastAPI** : [Guide](https://fastapi.tiangolo.com/)
- **Optuna** : [Tutoriels](https://optuna.readthedocs.io/)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez une branch (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -am 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©ez une Pull Request

## ğŸ“„ Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

**ğŸ¯ Projet dÃ©veloppÃ© dans le cadre d'un apprentissage MLOps appliquÃ© aux donnÃ©es climatiques**





â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Push Code â†’ GitHub Actions CI/CD Pipeline             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
    Tests (tests.yml)  Train (train.yml)  Docker (docker.yml)
        â”‚                  â”‚                  â”‚
   âœ… Unit Tests      âœ… DVC Pull      âœ… Security Scan
   âœ… Linting         âœ… Train Models   âœ… Build Images
   âœ… Coverage        âœ… Evaluate       âœ… Push to Docker Hub
                      âœ… MLflow Log
                      âœ… Register Best
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â–¼             â–¼
              Staging       Production