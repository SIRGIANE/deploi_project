FROM apache/airflow:2.8.0-python3.10

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

USER airflow

# Copy requirements
COPY airflow/requirements-airflow.txt /tmp/requirements-airflow.txt

# Create a minimal requirements file for Airflow (without TensorFlow)
RUN echo "pandas>=1.5.0\nnumpy>=1.21.0\nscikit-learn>=1.2.0\n\
mlflow>=2.0.0\ndvc>=3.0.0\ndvc-s3>=2.0.0\n\
fastapi>=0.95.0\nuvicorn>=0.20.0\npydantic>=1.10.0\n\
joblib>=1.2.0\npython-dotenv>=0.19.0\nrequests>=2.28.0\n\
pyyaml>=6.0\njinja2>=3.1.0\n\
evidently>=0.4.12\ngreat-expectations>=0.17.19\n\
optuna>=3.0.0\nstatsmodels>=0.13.0" > /tmp/requirements-minimal.txt

# Install minimal Python dependencies with increased timeout
RUN pip install --no-cache-dir \
    --default-timeout=1000 \
    -r /tmp/requirements-minimal.txt

# Install Airflow-specific requirements
RUN pip install --no-cache-dir \
    --default-timeout=1000 \
    -r /tmp/requirements-airflow.txt

# Set environment variables
ENV AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
ENV AIRFLOW__CORE__LOAD_EXAMPLES=false
ENV AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session
ENV AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true
ENV AIRFLOW__CORE__EXECUTOR=CeleryExecutor
ENV AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
ENV AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@airflow-postgres/airflow
ENV AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0

# Copy workspace
COPY . /workspace
WORKDIR /workspace

USER airflow